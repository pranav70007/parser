{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e17cac73",
   "metadata": {},
   "outputs": [],
   "source": [
    "class PipelineStage:\n",
    "    def __init__(self, config):\n",
    "        self.config = config\n",
    "\n",
    "    def run(self, data):\n",
    "        \"\"\"\n",
    "        data: dict containing the current document state\n",
    "        returns: dict (possibly augmented)\n",
    "        \"\"\"\n",
    "        raise NotImplementedError\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "493c65fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DocumentPipeline:\n",
    "    def __init__(self, stages):\n",
    "        self.stages = stages  # list of PipelineStage objects\n",
    "\n",
    "    def run(self, data):\n",
    "        for stage in self.stages:\n",
    "            print(f\"Running {stage.__class__.__name__}...\")\n",
    "            data = stage.run(data)\n",
    "        return data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6fbbb103",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "class PDFIngestor(PipelineStage):\n",
    "    def run(self, data):\n",
    "        from pdf2image import convert_from_path\n",
    "        pages = convert_from_path(self.config[\"pdf_path\"], dpi=300)\n",
    "        data[\"images\"] = [np.array(p) for p in pages]\n",
    "        return data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1c130faa",
   "metadata": {},
   "outputs": [],
   "source": [
    "class LayoutDetector(PipelineStage):\n",
    "    def run(self, data):\n",
    "        import deepdoctection as dd\n",
    "        layout_model = dd.get_model(\"layout\")  # pseudo-code\n",
    "        detections = layout_model(data[\"image\"])\n",
    "        data[\"layout\"] = detections\n",
    "        return data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4a9256a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MaskRegions(PipelineStage):\n",
    "    def run(self, data):\n",
    "        import cv2\n",
    "        image = data[\"image\"].copy()\n",
    "        for reg in data[\"layout\"]:\n",
    "            if reg[\"label\"] in self.config[\"remove_labels\"]:\n",
    "                x1,y1,x2,y2 = reg[\"bbox\"]\n",
    "                cv2.rectangle(image, (x1,y1), (x2,y2), (255,255,255), -1)\n",
    "        data[\"image\"] = image\n",
    "        return data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "97a48da5",
   "metadata": {},
   "outputs": [],
   "source": [
    "class LocalEnhancer(PipelineStage):\n",
    "    def run(self, data):\n",
    "        import cv2\n",
    "        img = data[\"image\"]\n",
    "        clahe = cv2.createCLAHE(clipLimit=2.0, tileGridSize=(8,8))\n",
    "        gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "        data[\"image\"] = clahe.apply(gray)\n",
    "        return data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "949831cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TesseractOCR(PipelineStage):\n",
    "    def run(self, data):\n",
    "        import pytesseract\n",
    "        text = pytesseract.image_to_string(data[\"image\"])\n",
    "        data[\"ocr_text\"] = text\n",
    "        return data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "3e20ed19",
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "libGL.so.1: cannot open shared object file: No such file or directory",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mImportError\u001b[39m                               Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[16]\u001b[39m\u001b[32m, line 2\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mpathlib\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m Path\n\u001b[32m----> \u001b[39m\u001b[32m2\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01myaml\u001b[39;00m,\u001b[38;5;250m \u001b[39m\u001b[34;01mcv2\u001b[39;00m\n\u001b[32m      3\u001b[39m \u001b[38;5;66;03m# load configuration\u001b[39;00m\n\u001b[32m      4\u001b[39m config = yaml.safe_load(\u001b[38;5;28mopen\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33mconfig.yml\u001b[39m\u001b[33m\"\u001b[39m))\n",
      "\u001b[31mImportError\u001b[39m: libGL.so.1: cannot open shared object file: No such file or directory"
     ]
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "import yaml, cv2\n",
    "# load configuration\n",
    "config = yaml.safe_load(open(\"config.yml\"))\n",
    "# define stages\n",
    "stages = [\n",
    "    PDFIngestor(config[\"ingest\"]),\n",
    "    LayoutDetector(config[\"layout\"]),\n",
    "    MaskRegions(config[\"mask\"]),\n",
    "    LocalEnhancer(config[\"enhance\"]),\n",
    "    TesseractOCR(config[\"ocr\"]),\n",
    "]\n",
    "# create pipeline\n",
    "pipe = DocumentPipeline(stages)\n",
    "# run on one document\n",
    "doc_data = {\"pdf_path\": \"sample_invoice.pdf\"}\n",
    "result = pipe.run(doc_data)\n",
    "print(result[\"ocr_text\"])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
